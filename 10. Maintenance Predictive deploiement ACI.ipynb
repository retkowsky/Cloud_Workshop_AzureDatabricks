{"cells":[{"cell_type":"markdown","source":["# Microsoft Azure AutoML Demo"],"metadata":{}},{"cell_type":"markdown","source":["Azure ML & Azure Databricks notebooks by Parashar Shah.\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."],"metadata":{}},{"cell_type":"markdown","source":["## Purpose and Challenge"],"metadata":{}},{"cell_type":"markdown","source":["The purpose of this notebook is for the user to build and deploy a Machine Learning (ML) application using Azure Machine Learning (AML) service. It is a predictive maintenance scenario based on https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan.\n\nThis notebook has the complete code to load, prep, train and deploy the model. We chose a small public data set for this demo so as to run the entire process in only few minutes.\n\nFollowing are the high level steps:\n\n1. Create AML Workspace\n2. Acquire and Prepare Data\n3. Automated ML\n4. Deploy Model as webservice\n5. Predictions"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Create cluster (in this lab it is pre-created)\n\nPlease follow the instructions from Microsoft documentation with your customers https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-environment#azure-databricks"],"metadata":{}},{"cell_type":"markdown","source":["## 2. Acquire and Prepare Data\nFor this notebook, we will use the NASA Prognostics Center's Turbo-Fan Failure dataset.  It is located here: https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan"],"metadata":{}},{"cell_type":"markdown","source":["Download and un-zip the data"],"metadata":{}},{"cell_type":"code","source":["import logging\nimport os\nimport random\nimport time\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport numpy as np\nimport pandas as pd"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# import needed libraries for downloading and unzipping the file\nimport urllib.request\nfrom zipfile import ZipFile"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# download from url\nresponse = urllib.request.urlopen(\"https://ti.arc.nasa.gov/c/6/\")\noutput = open('CMAPSSData.zip', 'wb')    # note the flag:  \"wb\"        \noutput.write(response.read())\noutput.close()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# unzip files\nzipfile = ZipFile(\"CMAPSSData.zip\")\nzipfile.extract(\"train_FD001.txt\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>&apos;/databricks/driver/train_FD001.txt&apos;\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["Next we read our data into a Pandas DataFrame.\nNote the headers were not in the space seperated txt file, so we assign them from the ReadMe in the zip file. In pandas we use read_csv with the delimiter option."],"metadata":{}},{"cell_type":"code","source":["train = pd.read_csv(\"train_FD001.txt\", delimiter=\"\\s|\\s\\s\", index_col=False, engine='python', names=['unit','cycle','os1','os2','os3','sm1','sm2','sm3','sm4','sm5','sm6','sm7','sm8','sm9','sm10','sm11','sm12','sm13','sm14','sm15','sm16','sm17','sm18','sm19','sm20','sm21'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["Take a quick look at the data"],"metadata":{}},{"cell_type":"code","source":["train.head(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>\n   unit  cycle     os1     os2   ...     sm18   sm19   sm20     sm21\n0     1      1 -0.0007 -0.0004   ...     2388  100.0  39.06  23.4190\n1     1      2  0.0019 -0.0003   ...     2388  100.0  39.00  23.4236\n2     1      3 -0.0043  0.0003   ...     2388  100.0  38.95  23.3442\n3     1      4  0.0007  0.0000   ...     2388  100.0  38.88  23.3739\n4     1      5 -0.0019 -0.0002   ...     2388  100.0  38.90  23.4044\n5     1      6 -0.0043 -0.0001   ...     2388  100.0  38.98  23.3669\n6     1      7  0.0010  0.0001   ...     2388  100.0  39.10  23.3774\n7     1      8 -0.0034  0.0003   ...     2388  100.0  38.97  23.3106\n8     1      9  0.0008  0.0001   ...     2388  100.0  39.05  23.4066\n9     1     10 -0.0033  0.0001   ...     2388  100.0  38.95  23.4694\n\n[10 rows x 26 columns]\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Our dataset has a number of units in it, with each engine flight listed as a cycle. The cycles count up until the engine fails. What we would like to predict is the no. of cycles until failure. \nSo we need to calculate a new column called RUL, or Remaining Useful Life.  It will be the last cycle value minus each cycle value per unit."],"metadata":{}},{"cell_type":"code","source":["# Assign ground truth\ndef assignrul(df):\n    maxi = df['cycle'].max()\n    df['rul'] = maxi - df['cycle']\n    return df\n    \n\ntrain_new = train.groupby('unit').apply(assignrul)\n\ntrain_new.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>\nIndex([&apos;unit&apos;, &apos;cycle&apos;, &apos;os1&apos;, &apos;os2&apos;, &apos;os3&apos;, &apos;sm1&apos;, &apos;sm2&apos;, &apos;sm3&apos;, &apos;sm4&apos;, &apos;sm5&apos;,\n       &apos;sm6&apos;, &apos;sm7&apos;, &apos;sm8&apos;, &apos;sm9&apos;, &apos;sm10&apos;, &apos;sm11&apos;, &apos;sm12&apos;, &apos;sm13&apos;, &apos;sm14&apos;,\n       &apos;sm15&apos;, &apos;sm16&apos;, &apos;sm17&apos;, &apos;sm18&apos;, &apos;sm19&apos;, &apos;sm20&apos;, &apos;sm21&apos;, &apos;rul&apos;],\n      dtype=&apos;object&apos;)\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["Now our dataframe has the 'RUL' column.  Predicting this value will be the objective of this exercise."],"metadata":{}},{"cell_type":"code","source":["train_new.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">8</span><span class=\"ansired\">]: </span>\n   unit  cycle     os1     os2    os3 ...   sm18   sm19   sm20     sm21  rul\n0     1      1 -0.0007 -0.0004  100.0 ...   2388  100.0  39.06  23.4190  191\n1     1      2  0.0019 -0.0003  100.0 ...   2388  100.0  39.00  23.4236  190\n2     1      3 -0.0043  0.0003  100.0 ...   2388  100.0  38.95  23.3442  189\n3     1      4  0.0007  0.0000  100.0 ...   2388  100.0  38.88  23.3739  188\n4     1      5 -0.0019 -0.0002  100.0 ...   2388  100.0  38.90  23.4044  187\n\n[5 rows x 27 columns]\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["First note that the sensor measurements do seem to be changing as we near 0 RUL. This implies that we should be able to make a model that will be useful enough for business value.\n\nWe are now ready to train a model on this data using Automated ML."],"metadata":{}},{"cell_type":"markdown","source":["## 3. Azure Automated ML"],"metadata":{}},{"cell_type":"markdown","source":["Here we utilize Azure's AutoML package to automate the scaling of the sensors, selection of sensors, and automatically train and evaluate many different types of ML models."],"metadata":{}},{"cell_type":"code","source":["import azureml.core\n\n# Check core SDK version number - based on build number of preview/master.\nprint(\"SDK version:\", azureml.core.VERSION)\n\nusername = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user').split(\"@\")[0]\nprint(\"Your username is {0}\".format(username))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">SDK version: 1.0.18\nYour username is seretkow\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["from azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.run import AutoMLRun"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["Provide your Machine Learning Workspace credentials to run AutoML. You will need to perform Microsoft's MFA. Please follow the manual auth instructions."],"metadata":{}},{"cell_type":"code","source":["subscription_id = \"70b8f39e-8863-49f7-b6ba-34a80799550c\" #you should be owner or contributor\nresource_group = \"mlserviceresourcegroup\" #you should be owner or contributor\nworkspace_name = \"MLServiceWorkspace\" #your workspace name\nworkspace_region = \"West Europe\" #your region"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["You can have more options when creating Workspace\n\nhttps://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py has more options."],"metadata":{}},{"cell_type":"code","source":["# Import the Workspace class and check the Azure ML SDK version.\nfrom azureml.core import Workspace\n\nws = Workspace.create(name = workspace_name,\n                      subscription_id = subscription_id,\n                      resource_group = resource_group, \n                      location = workspace_region,                      \n                      exist_ok=True)\nws.get_details()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>\n{&apos;containerRegistry&apos;: &apos;/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/mlserviceresourcegroup/providers/microsoft.containerregistry/registries/mlserviceworks2334900829&apos;,\n &apos;identityType&apos;: &apos;SystemAssigned&apos;,\n &apos;storageAccount&apos;: &apos;/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/mlserviceresourcegroup/providers/microsoft.storage/storageaccounts/mlserviceworks0764555666&apos;,\n &apos;identityTenantId&apos;: &apos;72f988bf-86f1-41af-91ab-2d7cd011db47&apos;,\n &apos;identityPrincipalId&apos;: &apos;b4335a6a-b27f-4b38-9f49-52ed442de49e&apos;,\n &apos;description&apos;: &apos;&apos;,\n &apos;id&apos;: &apos;/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourceGroups/mlserviceresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/MLServiceWorkspace&apos;,\n &apos;friendlyName&apos;: &apos;&apos;,\n &apos;keyVault&apos;: &apos;/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/mlserviceresourcegroup/providers/microsoft.keyvault/vaults/mlserviceworks0657942370&apos;,\n &apos;location&apos;: &apos;westeurope&apos;,\n &apos;type&apos;: &apos;Microsoft.MachineLearningServices/workspaces&apos;,\n &apos;name&apos;: &apos;MLServiceWorkspace&apos;,\n &apos;creationTime&apos;: &apos;2018-11-14T09:30:26.3955776+00:00&apos;,\n &apos;applicationInsights&apos;: &apos;/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/mlserviceresourcegroup/providers/microsoft.insights/components/mlserviceworks9069414308&apos;,\n &apos;workspaceid&apos;: &apos;f5bb1783-07f8-419d-a006-faaadbf5a5db&apos;}\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["from azureml.core import Workspace\n\nws = Workspace(workspace_name = workspace_name,\n               subscription_id = subscription_id,\n               resource_group = resource_group)\n\n# persist the subscription id, resource group name, and workspace name in aml_config/config.json.\nws.write_config(path=\"/databricks/driver/aml_config/\", file_name=\"config_{0}.json\".format(username))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Wrote the config file config_seretkow.json to: /databricks/driver/aml_config/config_seretkow.json\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["# Choose a name for the experiment and specify the project folder.\nexperiment_name = 'automl-predictive-rul'\nproject_folder = './sample_projects/automl-demo-predmain'\n\nexperiment = Experiment(ws, experiment_name)\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace Name'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\noutput['Experiment Name'] = experiment.name\npd.set_option('display.max_colwidth', -1)\npd.DataFrame(data = output, index = ['']).T"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">14</span><span class=\"ansired\">]: </span>\n                                                         \nExperiment Name    automl-predictive-rul                 \nLocation           westeurope                            \nProject Directory  ./sample_projects/automl-demo-predmain\nResource Group     mlserviceresourcegroup                \nSDK version        1.0.18                                \nSubscription ID    70b8f39e-8863-49f7-b6ba-34a80799550c  \nWorkspace Name     MLServiceWorkspace                    \n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["# put training data into X and Y df\nX_train = train_new.drop(['rul'], axis=1)[2:]\ny_train = train_new[['rul']][2:]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["X_train.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">16</span><span class=\"ansired\">]: </span>\n   unit  cycle   os1   os2    os3  ...   sm17  sm18   sm19  sm20  sm21\n2  1     3     -0.00 0.00  100.00  ...   390   2388 100.00 38.95 23.34\n3  1     4     0.00  0.00  100.00  ...   392   2388 100.00 38.88 23.37\n4  1     5     -0.00 -0.00 100.00  ...   393   2388 100.00 38.90 23.40\n5  1     6     -0.00 -0.00 100.00  ...   391   2388 100.00 38.98 23.37\n6  1     7     0.00  0.00  100.00  ...   392   2388 100.00 39.10 23.38\n\n[5 rows x 26 columns]\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["y_train.head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">17</span><span class=\"ansired\">]: </span>\n   rul\n2  189\n3  188\n4  187\n5  186\n6  185\n</div>"]}}],"execution_count":33},{"cell_type":"code","source":["X_test = train_new.drop(['rul'], axis=1)[0:1]\ny_test = train_new[['rul']][0:1]\nprint (X_test)\nprint (y_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   unit  cycle   os1   os2    os3  ...   sm17  sm18   sm19  sm20  sm21\n0  1     1     -0.00 -0.00 100.00  ...   392   2388 100.00 39.06 23.42\n\n[1 rows x 26 columns]\n   rul\n0  191\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["import azureml.dataprep as dprep\nimport uuid\n\nX_dflow = dprep.read_pandas_dataframe(X_train, temp_folder='/dbfs/tmp'+str(uuid.uuid4()))\ny_dflow = dprep.read_pandas_dataframe(y_train, temp_folder='/dbfs/tmp'+str(uuid.uuid4()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["y_dflow.get_profile()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">20</span><span class=\"ansired\">]: </span>\nColumnProfile:\n    column_name: rul\n    type: FieldType.INTEGER\n\n    min: 0.0\n    max: 361.0\n    count: 20629.0\n    missing_count: 0.0\n    not_missing_count: 20629.0\n    percent_missing: 0.0\n    error_count: 0.0\n    empty_count: 0.0\n\n\n    Quantiles:\n         0.1%: 0.0\n           1%: 20.12454935193565\n           5%: 19.23936170212766\n          25%: 50.991157863451086\n          50%: 102.58762669969065\n          75%: 155.34728036069126\n          95%: 228.81278684550742\n          99%: 287.4373469387753\n        99.9%: 341.9720666666661\n\n    mean: 107.79984487856936\n    std: 68.8795162043496\n    variance: 4744.387752545258\n    skewness: 0.5000932148957241\n    kurtosis: -0.21850756566908247\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["Now we are ready to configure Azure Automated ML.  We provide necessary information on: what we want to predict, what accuracy metric we want to use, how many models we want to try, and many other parameters. Automated ML will also automatically scale the data for us."],"metadata":{}},{"cell_type":"markdown","source":["## Configure Automated ML\n\nYou can use these params.\n\n|Property|Description|\n|-|-|\n|**task**|classification or regression|\n|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n|**primary_metric**|This is the metric that you want to optimize. Regression supports the following primary metrics: <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n|**iterations**|Number of iterations. In each iteration AutoML trains a specific pipeline with the data.|\n|**n_cross_validations**|Number of cross validation splits.|\n|**spark_context**|Spark Context object. for Databricks, use spark_context=sc|\n|**max_concurrent_iterations**|Maximum number of iterations to execute in parallel. This should be <= number of worker nodes in your Azure Databricks cluster.|\n|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n|**y**|(sparse) array-like, shape = [n_samples, ], [n_samples, n_classes]<br>Multi-class targets. An indicator matrix turns on multilabel classification. This should be an array of integers.|\n|**path**|Relative path to the project folder. AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder.|\n|**preprocess**|set this to True to enable pre-processing of data eg. string to numeric using one-hot encoding|\n|**exit_score**|Target score for experiment. It is associated with the metric. eg. exit_score=0.995 will exit experiment after that|"],"metadata":{}},{"cell_type":"code","source":["automl_config = AutoMLConfig(task = 'regression',\n                             debug_log = 'automl_errors_regression.log',\n                             primary_metric = 'r2_score',\n                             iteration_timeout_minutes = 5, #some runs may take 10+ mins hence limiting it for workshop\n                             iterations = 10, #you may change this to a higher number and see what happens\n                             #validation_size = 0.20, #for large datasets only and not needed for workshop\n                             verbosity = logging.INFO,\n                             max_concurrent_iterations = 2, #change it based on number of worker nodes\n                             spark_context=sc, #databricks/spark related\n                             n_cross_validations = 3, #(only needed for small datasets and if validation size is not set)\n                             X = X_dflow,\n                             y = y_dflow,\n                             preprocess=True, #preprocess\n                             path = project_folder)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["Finally we are ready to submit the experiment to Automated ML service. This step can take longer depending on the settings. AutoML will give us updates as models are trained and evaluated by the metric we specified above. The information from each ML model training will be stored in the Experiment section of the Azure ML Workspace in Azure Portal."],"metadata":{}},{"cell_type":"code","source":["local_run = experiment.submit(automl_config, show_output = True) # for higher runs please use show_output=False and use the below"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":41},{"cell_type":"code","source":["displayHTML(\"<a href={} target='_blank'>Your experiment in Azure Portal: {}</a>\".format(local_run.get_portal_url(), local_run.id))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<a href=https://mlworkspace.azure.ai/portal/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourceGroups/mlserviceresourcegroup/providers/Microsoft.MachineLearningServices/workspaces/MLServiceWorkspace/experiments/automl-predictive-rul/runs/AutoML_216baaf6-b766-4771-bbc4-e10ed0c96d74 target='_blank'>Your experiment in Azure Portal: AutoML_216baaf6-b766-4771-bbc4-e10ed0c96d74</a>"]}}],"execution_count":42},{"cell_type":"code","source":["# run this only after the portal shows experiment 'Completed'\nchildren = list(local_run.get_children())\nmetricslist = {}\nfor run in children:\n    properties = run.get_properties()\n    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}    \n    metricslist[int(properties['iteration'])] = metrics\n    hyperparamproperties = run.get_properties()\n    print(hyperparamproperties['run_properties'])\n\nrundata = pd.DataFrame(metricslist).sort_index(1)\nrundata"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">24</span><span class=\"ansired\">]: </span>\nEmpty DataFrame\nColumns: []\nIndex: []\n</div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["We want to keep the best model and deploy it as a service."],"metadata":{}},{"cell_type":"code","source":["# find the run with the highest accuracy value.\nbest_run, fitted_model = local_run.get_output()\nprint(best_run)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Exception</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-691515439878460&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># find the run with the highest accuracy value.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>best_run<span class=\"ansiyellow\">,</span> fitted_model <span class=\"ansiyellow\">=</span> local_run<span class=\"ansiyellow\">.</span>get_output<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> print<span class=\"ansiyellow\">(</span>best_run<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/azureml/train/automl/run.py</span> in <span class=\"ansicyan\">get_output</span><span class=\"ansiblue\">(self, iteration, metric)</span>\n<span class=\"ansigreen\">    395</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    396</span>             <span class=\"ansigreen\">if</span> curr_run <span class=\"ansigreen\">is</span> <span class=\"ansigreen\">None</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 397</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> Exception<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Could not find model with valid score for metric &apos;{0}&apos;&quot;</span><span class=\"ansiyellow\">.</span>format<span class=\"ansiyellow\">(</span>metric<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    398</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    399</span>         curr_run<span class=\"ansiyellow\">.</span>download_file<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span>model_name<span class=\"ansiyellow\">,</span> output_file_path<span class=\"ansiyellow\">=</span>model_local<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">Exception</span>: Could not find model with valid score for metric &apos;r2_score&apos;</div>"]}}],"execution_count":45},{"cell_type":"markdown","source":["## 4. Deploy Model"],"metadata":{}},{"cell_type":"code","source":["# register model in workspace & use the same in your score.py file\ndescription = 'AutoML-RUL-Regression-20190219'\ntags = None\nmodel=local_run.register_model(description=description, tags=tags)\nlocal_run.model_id # Use this id to deploy the model as a web service in Azure. Update score file with the output."],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["After we register the model in our AML Workspace, it should be visible in Azure Portal.\n\nNow we want to deploy the model as a REST API (real time webservice) that we can feed a row or rows of \"X\" data to, and return the predicted 'RUL' value.  To accomplish this, we will build a container image in our AML Workspace and deploy that image as a Container instance in Azure's ACI service.  We will then obtain an IP address where we can submit data and receive back the predicted 'RUL' value.\n\nThere are 3 things we need: \n1. A score.py file that contains the init() and run() functions with instructions on how to load and score with the model. Update the model name in this file.\n2. A mydeployenv.yml file that contains information on the python environment in which the model needs to run\n3. Configurations for our images and our services, using functions provided by AzureML service.\n\nThe cells below help you set these up."],"metadata":{}},{"cell_type":"code","source":["scorefilename = (('score'+str(uuid.uuid4()))[0:10]) + \".py\"\nprint(scorefilename) #change the filename in score file"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["%%writefile score270c9.py\n# Change the name based on the randomly generated filename\n# Scoring Script will need model id from registered model\nimport json\nimport numpy as np\nimport os\nimport pickle\nfrom sklearn.externals import joblib\nfrom sklearn.linear_model import LogisticRegression\n\nfrom azureml.core.model import Model\n\nimport azureml.train.automl\n\ndef init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('AutoML820abfb1abest') # update this based on previously registered model\n    print(model_path)\n    model = joblib.load(model_path)\n    \n\ndef run(raw_data):\n    # grab and prepare the data\n    data = (np.array(json.loads(raw_data)['data'])).reshape(1,-1)\n    # make prediction\n    y_hat = model.predict(data)\n    return json.dumps(y_hat.tolist())"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["condafilename = (('mydeploy'+str(uuid.uuid4()))[0:14]) + \".yml\"\nprint(condafilename) #change the filename in score file"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["from azureml.core.conda_dependencies import CondaDependencies\n\nmyenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn'], pip_packages=['azureml-sdk[automl]'])\n\nconda_env_file_name = condafilename\nmyenv.save_to_file('.', conda_env_file_name)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["from azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=2, \n                                               memory_gb=5, \n                                               tags={\"data\": \"RUL\",  \"method\" : \"sklearn\"}, \n                                               description='Predict RUL with Azure AutoML')"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":["Finally, configure the container image and deploy the service. Make sure the filenames match, your Workspace is in variable ws, and your model name is correct. It will create your containter image and deploy it as a webservice.\n\nThis process can take up to 10 minutes, so please be patient. You can check the progress bar periodically ..."],"metadata":{}},{"cell_type":"code","source":["# this will take 10-15 minutes to finish\n\nservice_name = \"rul-pred\" #change this to whatever other name you want\nruntime = \"python\" \ndriver_file = scorefilename #use the name generated earlier\nmy_conda_file = conda_env_file_name #use the name generated earlier\n\n# image creation\nfrom azureml.core.image import ContainerImage\nmyimage_config = ContainerImage.image_configuration(execution_script = driver_file, \n                                    runtime = runtime, \n                                    conda_file = my_conda_file)\n\n# Webservice creation\nmyservice = AciWebservice.deploy_from_model(\n  workspace=ws, \n  name=service_name,\n  deployment_config = aciconfig,\n  models = [model],\n  image_config = myimage_config\n    )\n\nmyservice.wait_for_deployment(show_output=True)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":["Just as a check, we can retrieve the URL for the scoring function."],"metadata":{}},{"cell_type":"code","source":["print(myservice.scoring_uri)"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":["Let's check to see if the service is working.  Here we submit a single row of data from X_train to see if it returns a reasonable prediction."],"metadata":{}},{"cell_type":"code","source":["test = X_test.values.tolist()\ntestlabel = y_test.values"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["import requests\nimport json\n\n# send a random row from the test set to score\n#random_index = np.random.randint(0, len(X_train)-1)\ninput_data = \"{\\\"data\\\": \" + str(test) + \"}\"\n\nheaders = {'Content-Type':'application/json'}\n\n# for AKS deployment you'd need to the service key in the header as well\n# api_key = service.get_key()\n# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n\nresp = requests.post(myservice.scoring_uri, input_data, headers=headers)\n\nprint(\"POST to url\", myservice.scoring_uri)\nprint(\"input data:\", input_data)\nprint(\"label:\", testlabel)\nprint(\"prediction:\", resp.text)"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["Here we see one engine evolving through many flights, or cycles.  As we approach failure, the rul declines to zero, as does the prediction.  This is a good example of how the predictive model can assist in estimate the future failure of the engine.\n\nNote that the model does not perform well at high rul.  This is an acceptable outcome as the engine is far from failure."],"metadata":{}},{"cell_type":"markdown","source":["To avoid any run-away Azure costs, we always delete un-necessary services when we are done."],"metadata":{}},{"cell_type":"code","source":["myservice.delete()"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":["You may deploy this docker image to AKS."],"metadata":{}},{"cell_type":"markdown","source":["## 5. Conclusions"],"metadata":{}},{"cell_type":"markdown","source":["We have executed an end-to-end Azure ML Service project with a real life example. We started with a problem at hand, created an Azure ML Workspace, downloaded a predictive maintenance dataset, processed the data, train a sophisticated model with Azure Automated ML, and deployed that model quickly and easily to ACI (AKS) using Azure's Machine Learning service."],"metadata":{}}],"metadata":{"kernelspec":{"display_name":"Python (env1231)","language":"python","name":"env1231"},"name":"10. Maintenance Predictive deploiement ACI","notebookId":691515439878414},"nbformat":4,"nbformat_minor":0}
